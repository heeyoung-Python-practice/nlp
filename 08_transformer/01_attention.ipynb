{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0733544",
   "metadata": {},
   "source": [
    "### Scaled Dot-Product Attention 계산 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 X: torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# batch_size, seq_len, embedding_dim\n",
    "x = torch.tensor(\n",
    "                [\n",
    "                    [\n",
    "                        [1.0, 0.0, 1.0, 0.0],\n",
    "                        [0.0, 2.0, 0.0, 2.0],\n",
    "                        [1.0, 1.0, 1.0, 1.0]\n",
    "                    ]\n",
    "                ]\n",
    ") # 배치 :1, 길이 :3, 차원:4\n",
    "print('입력 X:',x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : torch.Size([1, 3, 4])\n",
      "K : torch.Size([1, 3, 4])\n",
      "V : torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Q, K, V를 생성하는 선형층\n",
    "W_q = nn.Linear(4,4,bias=False) # Query 생성용 선형 변환(4 -> 4)\n",
    "W_k = nn.Linear(4,4,bias=False) # Key 생성용 선형 변환(4 -> 4)\n",
    "W_v = nn.Linear(4,4,bias=False) # Value 생성용 선형 변환(4 -> 4)\n",
    "\n",
    "# Q, K, V\n",
    "Q = W_q(x)  # x -> Q (배치, 길이, 차원)\n",
    "K = W_k(x)  # x -> K (배치, 길이, 차원)\n",
    "V = W_v(x)  # x -> V (배치, 길이, 차원)\n",
    "\n",
    "print(\"Q :\", Q.shape)\n",
    "print(\"K :\", K.shape)\n",
    "print(\"V :\", V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_scores : torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 1. Q, K, V 유사도 계산\n",
    "attn_scores = torch.matmul(Q, K.transpose(-2,-1)) # Q*k^V로 토큰간 유사도 (Score) 계산\n",
    "attn_scores /= Q.size(-1) ** 0.5            # 차원(d_k)로 나눠 score 스케일 조정(softmax 안정화)\n",
    "print(\"attn_scores :\", attn_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc2bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights : torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2. attention 분포(확률)\n",
    "attn_weights = F.softmax(attn_scores,dim=-1)    # 각 토큰이 바라볼 비율을 확률로 변환 (행 단위 합 = 1)\n",
    "print(\"attn_weights :\", attn_weights.shape)     # attention 가중치(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acee08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_value : torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 3. V_attention 분포의 가중합\n",
    "output = torch.matmul(attn_weights, V)      # attention 가중치로 V를 가중합해 최종 출력 생성\n",
    "print(\"attn_value :\",output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d0e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x : tensor([[[1., 0., 1., 0.],\n",
      "         [0., 2., 0., 2.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "\n",
      "Q : tensor([[[ 0.1408, -0.1067, -0.3542,  0.8163],\n",
      "         [-1.3424,  0.2069,  0.4467, -0.9321],\n",
      "         [-0.5304, -0.0032, -0.1308,  0.3502]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "K : tensor([[[-0.9428, -0.1939, -0.6027, -0.1414],\n",
      "         [ 1.1881, -1.4954, -0.0443, -1.4044],\n",
      "         [-0.3487, -0.9416, -0.6249, -0.8436]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "V : tensor([[[-0.2270, -0.1727,  0.0626, -0.1853],\n",
      "         [-1.6723,  0.1446,  1.6868,  0.0089],\n",
      "         [-1.0631, -0.1004,  0.9060, -0.1808]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "atteution 본포 : tensor([[[0.4013, 0.2704, 0.3283],\n",
      "         [0.4378, 0.1868, 0.3754],\n",
      "         [0.4551, 0.2003, 0.3447]]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "출력 output : tensor([[[-0.8923, -0.0632,  0.7786, -0.1313],\n",
      "         [-0.8109, -0.0863,  0.6826, -0.1473],\n",
      "         [-0.8046, -0.0842,  0.6786, -0.1449]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Attention 중간 결과 (Q/K/V)와 분포, 최종 출력 확인\n",
    "print(\"입력 x :\", x)    # 원본 입력값\n",
    "print(\"\\nQ :\", Q)\n",
    "print(\"\\nK :\", K)\n",
    "print(\"\\nV :\", V)\n",
    "\n",
    "print(\"\\nattention 본포 :\", attn_weights)\n",
    "print(\"\\n출력 output :\",output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a07935",
   "metadata": {},
   "source": [
    "### Multi-Head Attention (헤드 분할/결합) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3179272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 x: torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# batch_size, seq_len, embedding_dim\n",
    "x = torch.tensor([\n",
    "    [\n",
    "        [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "        [0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0],\n",
    "        [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "    ]\n",
    "])  # 배치 1, 길이 3, 차원 8\n",
    "print('입력 x:',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e47c0a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : torch.Size([1, 3, 8])\n",
      "K : torch.Size([1, 3, 8])\n",
      "V : torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "B, T, embedding_dim = x.shape           # B, T, E\n",
    "num_head = 4                            # 헤드 개수\n",
    "heading_dim = embedding_dim // num_head # 헤드당 차원(d_k)\n",
    "\n",
    "W_q = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "W_k = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "W_v = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "\n",
    "Q=W_q(x)\n",
    "K=W_k(x)\n",
    "V=W_v(x)\n",
    "\n",
    "print(\"Q :\",Q.shape)\n",
    "print(\"K :\",K.shape)\n",
    "print(\"V :\",V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c13bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_head: torch.Size([1, 4, 3, 2])\n",
      "K_head: torch.Size([1, 4, 3, 2])\n",
      "V_head: torch.Size([1, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 헤드 분할\n",
    "# B, T, embedding_dim\n",
    "# -> B, T, num_head, embedding_dim\n",
    "# -> B, num_head, T, embedding_dim\n",
    "Q_head = Q.view(B,T,num_head,heading_dim).transpose(1,2)        # Q를 헤드별로 쪼개고 (num_head) 차원 위치 교환\n",
    "K_head = K.view(B,T,num_head,heading_dim).transpose(1,2)        # K도 동일\n",
    "V_head = V.view(B,T,num_head,heading_dim).transpose(1,2)        # V도 동일\n",
    "\n",
    "print(\"Q_head:\",Q_head.shape)\n",
    "print(\"K_head:\",K_head.shape)\n",
    "print(\"V_head:\",V_head.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fba715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어텐션 스코어 : torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Q,K 유사도 계산\n",
    "attn_scores = torch.matmul(Q_head,K_head.transpose(-2,-1))      # 각 헤드별로 Q*K^T로 계산 (B,num_head,T,T)\n",
    "attn_scores /= embedding_dim ** 0.5                                # 스캐일링 (default)\n",
    "print(\"어텐션 스코어 :\",attn_scores.shape)                       # score shape 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f586e8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어테년 분포 : torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# attention 분포 게산\n",
    "attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "print(\"어테년 분포 :\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e734adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어텐션 분포 : torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# attnetion 분포 계산\n",
    "attn_weights = F.softmax(attn_weights, dim=-1)  # 마지막 축을 기준으로 sfotmax -> 확률 분포\n",
    "print(\"어텐션 분포 :\", attn_weights.shape)      # (B,num_head,T,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8591bdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 어텐션값 : torch.Size([1, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# V와 가중합 계산\n",
    "output = torch.matmul(attn_weights, V_head)     # 가중합 -> (B, num_head, T, heading_dim)\n",
    "print('출력 어텐션값 :', output.shape)          # 헤드별 출력 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력(헤드결합) : torch.Size([1, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "# 헤드 결합\n",
    "output = output.transpose(1,2)  # *B, num_headm T, d_k) -> (B,T,num_head,d_k)\n",
    "output = output.contiguous().view(B,T,embedding_dim)    # (B, T, num_hdad*d_k) -> (B, T, d_model)\n",
    "print(\"출력(헤드결합) :\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81beb493",
   "metadata": {},
   "source": [
    "tensor.contiguous() : view() 호출하기 전 메모리의 연속된 상태를 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4bba4",
   "metadata": {},
   "source": [
    "## 일반 Attention vs Multi-Head Attention\n",
    "\n",
    "(1) 같은 문장에서도 “관계”는 여러 종류라서\n",
    "예: “나는 어제 은행에 갔다”\n",
    "“은행”이 finance인지 river bank인지 문맥으로 판단해야 함\n",
    "어떤 헤드는 “시간/장소 단서”에\n",
    "다른 헤드는 “주변 단어 의미”에\n",
    "또 다른 헤드는 “문장 전역 정보”에 집중하는 식으로 동시에 여러 관계를 잡아냄\n",
    "\n",
    "(2) 긴 문장/복잡한 문맥에서 더 잘 버팀\n",
    "싱글 attention은 전역을 다 보긴 하지만 “한 가지 정렬”로만 보니까,\n",
    "복잡한 의존성이 많아질수록 한 번에 잡기 힘든데\n",
    "MHA는 여러 헤드가 분산해서 잡아주니 안정적.\n",
    "\n",
    "(3) 병렬 연산이 잘 맞아서(Transformer의 장점 극대화)\n",
    "RNN처럼 순차가 아니라 행렬곱 중심이라 GPU에서 효율이 좋고,\n",
    "MHA는 “여러 attention을 병렬로” 돌려도 구조적으로 잘 맞음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c0978",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
